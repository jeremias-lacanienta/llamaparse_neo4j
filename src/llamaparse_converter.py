#!/usr/bin/env python3
"""
Contract JSON Enhancer

This script enhances contract JSON data with SpaCy and ContractBERT NLP analysis.
It takes a JSON file (previously generated by LlamaParse) and adds entity recognition
and semantic annotations to improve contract analysis.
"""

import os
import sys
import json
import argparse
from datetime import datetime
import spacy
from transformers import pipeline

# Load NLP models
nlp = spacy.load("en_core_web_lg")
contractbert_ner = None
contractbert_classifier = None

def initialize_nlp_models():
    """Initialize NLP models for contract analysis."""
    global contractbert_ner, contractbert_classifier
    
    print("Loading ContractBERT NER model...")
    contractbert_ner = pipeline("token-classification", 
                               model="nlpaueb/legal-bert-base-uncased", 
                               aggregation_strategy="simple")
    
    print("Loading ContractBERT classifier model...")
    contractbert_classifier = pipeline("text-classification", 
                                     model="nlpaueb/legal-bert-base-uncased")
    
    print("NLP models loaded successfully")

def enhance_contract_json(input_file, output_file=None):
    """Enhance a contract JSON file with advanced NLP models.
    
    Takes a JSON file (previously generated by LlamaParse or similar tool)
    and enhances it with SpaCy and ContractBERT NLP analysis.
    """
    # Initialize NLP models if not already initialized
    if contractbert_ner is None:
        initialize_nlp_models()
    
    # Determine output file if not provided
    if output_file is None:
        base_name = os.path.splitext(input_file)[0]
        output_file = f"{base_name}_enhanced.json"
    
    try:
        # Load the JSON data
        print(f"Loading JSON data from: {input_file}")
        with open(input_file, 'r') as f:
            parsed_data = json.load(f)
        
        # Check if the parsed data is a list (array) or dictionary
        if isinstance(parsed_data, list):
            # If it's a list, enhance each item in the list
            enhanced_data = []
            for item in parsed_data:
                enhanced_item = enhance_with_nlp(item)
                enhanced_data.append(enhanced_item)
        else:
            # If it's a dictionary, enhance it directly
            enhanced_data = enhance_with_nlp(parsed_data)
        
        # Write output to file
        with open(output_file, 'w') as f:
            json.dump(enhanced_data, f, indent=2)
            
        print(f"Successfully enhanced contract data and saved to: {output_file}")
        return enhanced_data
        
    except Exception as e:
        print(f"Error enhancing contract data: {e}")
        sys.exit(1)

def enhance_with_nlp(parsed_data):
    """Enhance parsed contract data with SpaCy and ContractBERT analysis."""
    enhanced_data = parsed_data.copy()
    
    # Add NLP metadata
    enhanced_data["metadata"] = enhanced_data.get("metadata", {})
    enhanced_data["metadata"]["nlp_enhancement"] = {
        "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        "models": {
            "spacy": "en_core_web_lg",
            "contractbert": "legal-bert-base-uncased"
        }
    }
    
    # Process pages with NLP
    if "pages" in enhanced_data:
        for i, page in enumerate(enhanced_data["pages"]):
            if "text" in page:
                # Process text with SpaCy
                page_text = page["text"]
                doc = nlp(page_text[:10000])  # Limit to 10,000 chars per page for memory
                
                # Extract named entities
                entities = []
                for ent in doc.ents:
                    entities.append({
                        "text": ent.text,
                        "label": ent.label_,
                        "start": ent.start_char,
                        "end": ent.end_char
                    })
                
                # Process with ContractBERT for legal entities
                if len(page_text) > 450:
                    chunks = [page_text[j:j+450] for j in range(0, min(len(page_text), 5000), 450)]
                    for chunk in chunks:
                        bert_entities = contractbert_ner(chunk)
                        for entity in bert_entities:
                            entity_type = entity.get("entity_group", "")
                            if entity_type in ["PERSON", "ORG", "DATE", "MONEY", "LAW"]:
                                entities.append({
                                    "text": entity.get("word", ""),
                                    "label": entity_type,
                                    "start": entity.get("start", 0),
                                    "end": entity.get("end", 0),
                                    "source": "contractbert"
                                })
                else:
                    bert_entities = contractbert_ner(page_text)
                    for entity in bert_entities:
                        entity_type = entity.get("entity_group", "")
                        if entity_type in ["PERSON", "ORG", "DATE", "MONEY", "LAW"]:
                            entities.append({
                                "text": entity.get("word", ""),
                                "label": entity_type,
                                "start": entity.get("start", 0),
                                "end": entity.get("end", 0),
                                "source": "contractbert"
                            })
                
                # Add annotations to the page
                page["nlp_annotations"] = {
                    "entities": entities,
                }
    
    return enhanced_data

def main():
    """Main function for CLI usage."""
    parser = argparse.ArgumentParser(description="Enhance contract JSON with NLP analysis")
    
    parser.add_argument("input", help="Path to the input JSON file containing contract data")
    parser.add_argument("-o", "--output", help="Path to save the enhanced JSON (defaults to input_enhanced.json)")
    
    args = parser.parse_args()
    
    # Process the contract JSON
    enhance_contract_json(args.input, args.output)

if __name__ == "__main__":
    main()